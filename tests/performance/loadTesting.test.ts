/**\n * Performance and load testing for SocialPulse platform\n */\n\nimport { HyperliquidClient } from '../../src/services/hyperliquid';\nimport { createLargeDataset, createMockTraderList, generateTimeSeriesData } from '../utils/mockData';\n\n// Mock dependencies for performance testing\njest.mock('axios');\njest.mock('ethers');\n\ndescribe('Performance and Load Testing', () => {\n  let client: HyperliquidClient;\n  let mockAxios: any;\n\n  beforeAll(() => {\n    const axios = require('axios');\n    mockAxios = {\n      post: jest.fn(),\n      create: jest.fn().mockReturnThis()\n    };\n    axios.create.mockReturnValue(mockAxios);\n\n    client = new HyperliquidClient({\n      apiUrl: 'https://test-api.hyperliquid.xyz',\n      wsUrl: 'wss://test-api.hyperliquid.xyz/ws',\n      chainId: 1337\n    });\n  });\n\n  describe('Data Processing Performance', () => {\n    it('should handle large trader datasets efficiently', async () => {\n      const largeDataset = createLargeDataset('large');\n      const { traders } = largeDataset;\n\n      // Mock API response with large dataset\n      mockAxios.post.mockResolvedValue({ data: traders });\n\n      const startTime = performance.now();\n      const result = await client.getTopTraders(1000);\n      const endTime = performance.now();\n\n      const processingTime = endTime - startTime;\n      \n      expect(result).toHaveLength(1000);\n      expect(processingTime).toBeLessThan(1000); // Should process within 1 second\n      \n      // Memory usage should be reasonable\n      const memoryUsage = (performance as any).memory?.usedJSHeapSize || 0;\n      expect(memoryUsage).toBeLessThan(100 * 1024 * 1024); // Less than 100MB\n    });\n\n    it('should efficiently sort and filter large trader lists', () => {\n      const traders = createMockTraderList(5000);\n      \n      // Test sorting performance\n      const sortStartTime = performance.now();\n      const sortedByROI = [...traders].sort((a, b) => b.roi - a.roi);\n      const sortEndTime = performance.now();\n      \n      expect(sortEndTime - sortStartTime).toBeLessThan(100); // Sort within 100ms\n      expect(sortedByROI[0].roi).toBeGreaterThanOrEqual(sortedByROI[1].roi);\n      \n      // Test filtering performance\n      const filterStartTime = performance.now();\n      const filteredTraders = traders.filter(trader => \n        trader.roi > 10 && \n        trader.winRate > 50 && \n        trader.maxDrawdown < 30\n      );\n      const filterEndTime = performance.now();\n      \n      expect(filterEndTime - filterStartTime).toBeLessThan(50); // Filter within 50ms\n      expect(filteredTraders.length).toBeGreaterThan(0);\n      \n      // Verify filter conditions\n      filteredTraders.forEach(trader => {\n        expect(trader.roi).toBeGreaterThan(10);\n        expect(trader.winRate).toBeGreaterThan(50);\n        expect(trader.maxDrawdown).toBeLessThan(30);\n      });\n    });\n\n    it('should handle concurrent data processing efficiently', async () => {\n      const datasets = Array.from({ length: 10 }, () => createMockTraderList(100));\n      \n      const startTime = performance.now();\n      \n      // Process multiple datasets concurrently\n      const results = await Promise.all(\n        datasets.map(async (dataset, index) => {\n          // Simulate some processing time\n          await new Promise(resolve => setTimeout(resolve, Math.random() * 10));\n          \n          return {\n            index,\n            processed: dataset.map(trader => ({\n              address: trader.address,\n              score: trader.roi * trader.winRate / (trader.maxDrawdown + 1)\n            })),\n            topPerformer: dataset.reduce((best, current) => \n              current.roi > best.roi ? current : best\n            )\n          };\n        })\n      );\n      \n      const endTime = performance.now();\n      \n      expect(results).toHaveLength(10);\n      expect(endTime - startTime).toBeLessThan(500); // Complete within 500ms\n      \n      results.forEach((result, index) => {\n        expect(result.index).toBe(index);\n        expect(result.processed).toHaveLength(100);\n        expect(result.topPerformer).toBeDefined();\n      });\n    });\n  });\n\n  describe('API Performance', () => {\n    it('should handle high-frequency API calls efficiently', async () => {\n      // Mock successful API responses\n      mockAxios.post.mockResolvedValue({\n        data: { status: 'ok', data: {} }\n      });\n\n      const apiCalls = [];\n      const startTime = performance.now();\n      \n      // Simulate 100 concurrent API calls\n      for (let i = 0; i < 100; i++) {\n        apiCalls.push(\n          client.getAccountInfo(`0x${i.toString().padStart(40, '0')}`)\n        );\n      }\n      \n      const results = await Promise.all(apiCalls);\n      const endTime = performance.now();\n      \n      expect(results).toHaveLength(100);\n      expect(endTime - startTime).toBeLessThan(2000); // Complete within 2 seconds\n      expect(mockAxios.post).toHaveBeenCalledTimes(100);\n    });\n\n    it('should handle API rate limiting gracefully', async () => {\n      let callCount = 0;\n      \n      // Mock rate limiting after 10 calls\n      mockAxios.post.mockImplementation(() => {\n        callCount++;\n        if (callCount <= 10) {\n          return Promise.resolve({ data: { status: 'ok' } });\n        } else {\n          return Promise.reject({\n            response: {\n              status: 429,\n              data: { error: 'Rate limit exceeded', retryAfter: 100 }\n            }\n          });\n        }\n      });\n\n      const startTime = performance.now();\n      const results = [];\n      const errors = [];\n      \n      // Make 20 API calls\n      for (let i = 0; i < 20; i++) {\n        try {\n          const result = await client.getMarkets();\n          results.push(result);\n        } catch (error) {\n          errors.push(error);\n        }\n      }\n      \n      const endTime = performance.now();\n      \n      expect(results).toHaveLength(10); // First 10 succeed\n      expect(errors).toHaveLength(10); // Next 10 fail due to rate limiting\n      expect(endTime - startTime).toBeLessThan(1000); // Fail fast\n      \n      // Verify rate limit errors\n      errors.forEach(error => {\n        expect(error.response.status).toBe(429);\n        expect(error.response.data.error).toBe('Rate limit exceeded');\n      });\n    });\n\n    it('should optimize batch API requests', async () => {\n      const addresses = Array.from({ length: 50 }, (_, i) => \n        `0x${i.toString().padStart(40, '0')}`\n      );\n      \n      // Mock batch API response\n      mockAxios.post.mockImplementation((url, data) => {\n        if (data.type === 'batchAccountInfo') {\n          return Promise.resolve({\n            data: data.addresses.map((addr: string) => ({\n              address: addr,\n              marginSummary: { accountValue: '10000', totalNtlPos: '1000' },\n              assetPositions: []\n            }))\n          });\n        }\n        return Promise.resolve({ data: {} });\n      });\n\n      const startTime = performance.now();\n      \n      // Simulate batch request (would be implemented in actual client)\n      const batchResult = await mockBatchAccountInfo(addresses);\n      \n      const endTime = performance.now();\n      \n      expect(batchResult).toHaveLength(50);\n      expect(endTime - startTime).toBeLessThan(200); // Much faster than individual calls\n      expect(mockAxios.post).toHaveBeenCalledTimes(1); // Single batch call\n    });\n  });\n\n  describe('WebSocket Performance', () => {\n    let mockWebSocket: any;\n\n    beforeEach(() => {\n      mockWebSocket = {\n        readyState: WebSocket.OPEN,\n        send: jest.fn(),\n        close: jest.fn(),\n        onmessage: null\n      };\n      \n      global.WebSocket = jest.fn().mockImplementation(() => mockWebSocket);\n    });\n\n    it('should handle high-frequency WebSocket messages efficiently', () => {\n      const messageHandler = jest.fn();\n      const startTime = performance.now();\n      \n      client.connectWebSocket(messageHandler);\n      \n      // Simulate 1000 rapid messages\n      for (let i = 0; i < 1000; i++) {\n        const mockMessage = {\n          type: 'trade',\n          data: {\n            coin: 'BTC',\n            side: i % 2 === 0 ? 'buy' : 'sell',\n            price: 47000 + Math.random() * 1000,\n            size: Math.random() * 2,\n            timestamp: Date.now() + i\n          }\n        };\n        \n        if (mockWebSocket.onmessage) {\n          mockWebSocket.onmessage({\n            data: JSON.stringify(mockMessage)\n          });\n        }\n      }\n      \n      const endTime = performance.now();\n      \n      expect(messageHandler).toHaveBeenCalledTimes(1000);\n      expect(endTime - startTime).toBeLessThan(100); // Process within 100ms\n    });\n\n    it('should efficiently manage multiple WebSocket subscriptions', () => {\n      const traderAddresses = Array.from({ length: 100 }, (_, i) => \n        `0x${i.toString().padStart(40, '0')}`\n      );\n      \n      client.connectWebSocket(() => {});\n      \n      const startTime = performance.now();\n      \n      // Subscribe to 100 traders\n      traderAddresses.forEach(address => {\n        client.subscribeToUserEvents(address);\n      });\n      \n      const endTime = performance.now();\n      \n      expect(mockWebSocket.send).toHaveBeenCalledTimes(100);\n      expect(endTime - startTime).toBeLessThan(50); // Subscribe within 50ms\n    });\n\n    it('should handle WebSocket message queuing efficiently', () => {\n      const messageQueue: any[] = [];\n      const batchSize = 10;\n      const processingDelay = 50;\n      \n      const queuedMessageHandler = (message: any) => {\n        messageQueue.push(message);\n        \n        // Process in batches to improve performance\n        if (messageQueue.length >= batchSize) {\n          setTimeout(() => {\n            const batch = messageQueue.splice(0, batchSize);\n            processBatch(batch);\n          }, processingDelay);\n        }\n      };\n      \n      client.connectWebSocket(queuedMessageHandler);\n      \n      const startTime = performance.now();\n      \n      // Send 50 messages rapidly\n      for (let i = 0; i < 50; i++) {\n        if (mockWebSocket.onmessage) {\n          mockWebSocket.onmessage({\n            data: JSON.stringify({ id: i, data: `message-${i}` })\n          });\n        }\n      }\n      \n      const queueTime = performance.now();\n      \n      expect(messageQueue.length).toBe(50);\n      expect(queueTime - startTime).toBeLessThan(10); // Queuing should be very fast\n      \n      // Wait for batch processing\n      setTimeout(() => {\n        expect(messageQueue.length).toBeLessThan(50); // Some messages processed\n      }, processingDelay * 2);\n    });\n  });\n\n  describe('Memory Management', () => {\n    it('should not leak memory during continuous operation', async () => {\n      const initialMemory = (performance as any).memory?.usedJSHeapSize || 0;\n      \n      // Simulate continuous operations for memory leak detection\n      for (let cycle = 0; cycle < 10; cycle++) {\n        const traders = createMockTraderList(100);\n        \n        // Process data\n        const processed = traders.map(trader => ({\n          id: trader.address,\n          score: calculateTraderScore(trader),\n          risk: calculateRiskLevel(trader)\n        }));\n        \n        // Simulate some operations\n        processed.sort((a, b) => b.score - a.score);\n        processed.filter(p => p.risk < 0.5);\n        \n        // Force garbage collection if available\n        if (global.gc) {\n          global.gc();\n        }\n      }\n      \n      const finalMemory = (performance as any).memory?.usedJSHeapSize || 0;\n      const memoryIncrease = finalMemory - initialMemory;\n      \n      // Memory increase should be minimal (less than 10MB)\n      expect(memoryIncrease).toBeLessThan(10 * 1024 * 1024);\n    });\n\n    it('should efficiently handle large data structures', () => {\n      const largeDataset = createLargeDataset('xl');\n      const startMemory = (performance as any).memory?.usedJSHeapSize || 0;\n      \n      // Create indices for fast lookups\n      const traderIndex = new Map();\n      const performanceIndex = new Map();\n      \n      const startTime = performance.now();\n      \n      largeDataset.traders.forEach(trader => {\n        traderIndex.set(trader.address, trader);\n        \n        const performanceKey = `${Math.floor(trader.roi / 10)}-${Math.floor(trader.winRate / 10)}`;\n        if (!performanceIndex.has(performanceKey)) {\n          performanceIndex.set(performanceKey, []);\n        }\n        performanceIndex.get(performanceKey).push(trader.address);\n      });\n      \n      const indexTime = performance.now();\n      const endMemory = (performance as any).memory?.usedJSHeapSize || 0;\n      \n      expect(indexTime - startTime).toBeLessThan(1000); // Index creation within 1 second\n      expect(traderIndex.size).toBe(largeDataset.traders.length);\n      expect(endMemory - startMemory).toBeLessThan(50 * 1024 * 1024); // Memory usage reasonable\n      \n      // Test fast lookups\n      const lookupStart = performance.now();\n      const randomAddress = largeDataset.traders[Math.floor(Math.random() * largeDataset.traders.length)].address;\n      const foundTrader = traderIndex.get(randomAddress);\n      const lookupEnd = performance.now();\n      \n      expect(foundTrader).toBeDefined();\n      expect(lookupEnd - lookupStart).toBeLessThan(1); // Lookup within 1ms\n    });\n  });\n\n  describe('Stress Testing', () => {\n    it('should handle extreme load conditions', async () => {\n      const concurrentOperations = [];\n      const operationCount = 50;\n      \n      // Mock various API responses\n      mockAxios.post.mockImplementation(() => {\n        const delay = Math.random() * 100; // Random delay 0-100ms\n        return new Promise(resolve => {\n          setTimeout(() => {\n            resolve({ data: { status: 'ok', timestamp: Date.now() } });\n          }, delay);\n        });\n      });\n      \n      const startTime = performance.now();\n      \n      // Create multiple concurrent operations\n      for (let i = 0; i < operationCount; i++) {\n        concurrentOperations.push(\n          performStressTestOperation(client, i)\n        );\n      }\n      \n      const results = await Promise.all(concurrentOperations);\n      const endTime = performance.now();\n      \n      expect(results).toHaveLength(operationCount);\n      expect(results.every(r => r.success)).toBe(true);\n      expect(endTime - startTime).toBeLessThan(5000); // Complete within 5 seconds\n    });\n\n    it('should recover from failures gracefully', async () => {\n      let failureCount = 0;\n      const maxFailures = 5;\n      \n      mockAxios.post.mockImplementation(() => {\n        if (failureCount < maxFailures) {\n          failureCount++;\n          return Promise.reject(new Error('Temporary failure'));\n        }\n        return Promise.resolve({ data: { status: 'ok' } });\n      });\n      \n      const results = [];\n      const errors = [];\n      \n      // Attempt operations with retry logic\n      for (let i = 0; i < 10; i++) {\n        try {\n          const result = await retryOperation(\n            () => client.getMarkets(),\n            { maxRetries: 3, delay: 100 }\n          );\n          results.push(result);\n        } catch (error) {\n          errors.push(error);\n        }\n      }\n      \n      expect(results.length + errors.length).toBe(10);\n      expect(errors.length).toBeLessThanOrEqual(maxFailures);\n      expect(results.length).toBeGreaterThan(0);\n    });\n  });\n});\n\n// Helper functions\nfunction calculateTraderScore(trader: any): number {\n  return (trader.roi * 0.4) + (trader.winRate * 0.3) + ((100 - trader.maxDrawdown) * 0.3);\n}\n\nfunction calculateRiskLevel(trader: any): number {\n  return (trader.maxDrawdown / 100) * 0.6 + ((100 - trader.winRate) / 100) * 0.4;\n}\n\nasync function mockBatchAccountInfo(addresses: string[]) {\n  // Simulate batch API call\n  return addresses.map(addr => ({\n    address: addr,\n    accountValue: 10000 + Math.random() * 50000,\n    totalNtlPos: 1000 + Math.random() * 5000\n  }));\n}\n\nfunction processBatch(batch: any[]) {\n  // Simulate batch processing\n  return batch.map(item => ({ ...item, processed: true }));\n}\n\nasync function performStressTestOperation(client: HyperliquidClient, index: number) {\n  try {\n    // Simulate various operations\n    const operations = [\n      () => client.getMarkets(),\n      () => client.getAccountInfo(`0x${index.toString().padStart(40, '0')}`),\n      () => client.getOrderBook('BTC'),\n      () => client.getCandles('ETH', '1h')\n    ];\n    \n    const operation = operations[index % operations.length];\n    await operation();\n    \n    return { success: true, index, operation: operation.name };\n  } catch (error) {\n    return { success: false, index, error: error.message };\n  }\n}\n\nasync function retryOperation<T>(\n  operation: () => Promise<T>,\n  options: { maxRetries: number; delay: number }\n): Promise<T> {\n  let attempt = 0;\n  \n  while (attempt < options.maxRetries) {\n    try {\n      return await operation();\n    } catch (error) {\n      attempt++;\n      if (attempt >= options.maxRetries) {\n        throw error;\n      }\n      await new Promise(resolve => setTimeout(resolve, options.delay));\n    }\n  }\n  \n  throw new Error('Max retries exceeded');\n}"